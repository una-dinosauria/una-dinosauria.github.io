<!doctype html>
<html lang="en">
	<!-- 
	        		   __    _       _ _      _        _                   _         _ _
                      / _)  (_)_   _| (_) ___| |_ __ _( )__  __      _____| |__  ___(_) |_ ___
             _.----._/ /    | | | | | | |/ _ \ __/ _` |/ __| \ \ /\ / / _ \ '_ \/ __| | __/ _ \
            /         /     | | |_| | | |  __/ || (_| |\__ \  \ V  V /  __/ |_) \__ \ | ||  __/
         __/ (  | (  |     _/ |\__,_|_|_|\___|\__\__,_||___/   \_/\_/ \___|_.__/|___/_|\__\___|
        /__.-'|_|--|_|    |__/
	-->
  	<head>
		<!-- Global site tag (gtag.js) - Google Analytics -->
		<script async src="https://www.googletagmanager.com/gtag/js?id=G-17RE2EP8JX"></script>
		<script>
		window.dataLayer = window.dataLayer || [];
		function gtag(){dataLayer.push(arguments);}
		gtag('js', new Date());

		gtag('config', 'G-17RE2EP8JX');
		</script>

		<meta charset="utf-8">
		<meta name="viewport" content="width=device-width, initial-scale=1">

		<!-- Bootstrap CSS -->
		<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.2.0-beta1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-0evHe/X+R7YkIZDRvuzKMRqM+OrBnVFBL6DOitfPri4tjfHxaWutUpFmBp4vmVor" crossorigin="anonymous">
		<!-- font awesome icons -->
		<script src="https://use.fontawesome.com/89e6d71bc3.js"></script>
		<!-- academicons -->
		<link rel="stylesheet" href="https://cdn.rawgit.com/jpswalsh/academicons/master/css/academicons.min.css">
		<!-- custom stylesheet can tweak bootstrap, see https://getbootstrap.com/docs/5.2/customize/css-variables/ -->
		<link rel="stylesheet" href="css/custom.css">

		<title>Julieta :D</title>
  	</head>

  	<body>
		<!-- <div class="jumbotron"> -->
		<!-- class formerly known as jumbotron does not exist anymore on bootstrap 5 :'( ... -->
		<div class="p-5 rounded-3" style="background-color: #eee; margin-bottom: 2rem">
			<div class="container">
				<strong></strong><h1 class="display-1">Hi! I'm Julieta :D</h1></strong>
				<p class="lead">In 2021 I joined <a href="https://waabi.ai/">Waabi</a>. You should <a href="https://jobs.lever.co/waabi">join us</a>!</p>
				<p class="lead">From 2018 to 2020 I was at <a href="https://www.uber.com/info/atg/">Uber ATG</a> Toronto, working with <a href="https://www.cs.toronto.edu/~urtasun/">Raquel Urtasun</a>.</p>
				<p class="lead">In the fall of 2016 I visited <a href="https://ps.is.tuebingen.mpg.de/person/black">Michael Black</a> and <a href="https://ps.is.tuebingen.mpg.de/person/jromero/">Javier Romero</a> in the <a href="https://ps.is.tuebingen.mpg.de/">Perceiving Systems</a> group at <a href="https://is.tuebingen.mpg.de/">MPI Tuebingen</a>.</p>
				<p class="lead">From 2015 to 2018 I was a PhD student in the <a href="https://www.cs.ubc.ca">Department of Computer Science</a>
				at the <a href="https://www.ubc.ca">University of British Columbia</a>,
				supervised by <a href="https://www.cs.ubc.ca/~little">Jim Little</a> and <a href="https://www.cs.ubc.ca/~hoos">Holger Hoos</a>.
				</p>
				<p class="lead">From 2012 to 2014 I got an MSc from the same university, working with the same nice people.</p>
				<p class="lead">Before that I was in <a href="https://www.youtube.com/watch?v=JsUt2jsLM1k">Mexico</a>.</p>
				<p class="lead">
				<a href="mailto:jltmtzc@gmail.com">email</a> /
				<a href="https://twitter.com/yoknapathawa">twitter</a> /
				<a href="https://github.com/una-dinosauria">github</a> /
				<a href="https://scholar.google.ca/citations?user=XFFTY50AAAAJ&hl=en">google scholar</a> /
				<a href="https://www.linkedin.com/in/julmtz/">linkedin</a>
				</p>
			</div>
		</div>

		<main>
		<div class="container">
			<h2>Selected papers</h2>
			<div class="row" data-masonry='{"percentPosition": true }'>
				<div class="col-sm-6 col-lg-4 mb-4">
					<div class="card mb-3">
						<a href="imgs/arxiv21.png"><img class="card-img-top img-fluid" src="imgs/arxiv21.png" alt="Diagram of our system for joint localization, perception, and prediction"></a>
						<div class="card-body">
							<h4 class="card-title">Joint localization, perception, and prediction</h4>
							<p class="card-text">
							John Phillips, <strong>Julieta Martinez</strong>, Ioan Andrei Bârsan, Sergio Casas, Abbas Sadat, and Raquel Urtasun.<br>
							<em>Deep Multi-Task Learning for Joint Localization, Perception, and Prediction.</em>
							In <strong>CVPR 2021</strong><br />
							We design an architecture that jointly performs vehicle ego-localization, object detection, and motion forecasting.</p>
						</div>
						<div class="card-footer">
							<a href="https://arxiv.org/pdf/2101.06720.pdf"><i class="fa fa-file-pdf-o fa-lg"></i></a>
							<a href="https://arxiv.org/abs/2101.06720"><i class="ai ai-arxiv ai-lg"></i></a>
							<a href="papers/bibtex/arxiv21.bib">.bib</a>
						</div>
					</div>
				</div>
				<div class="col-sm-6 col-lg-4 mb-4">
					<div class="card">
						<a href="imgs/cvpr21.png"><img class="card-img-top img-fluid" src="imgs/cvpr21.png" alt="Card image cap"></a>
						<div class="card-body mb-3">
							<h4 class="card-title">Neural network compression</h4>
							<p class="card-text">
							<strong>Julieta Martinez*</strong>, Jashan Shewakramani*, Ting Wei Liu*, Ioan Andrei Bârsan, Wenyuan Zeng, and Raquel Urtasun.<br>
							<em>Permute, Quantize, and Fine-tune: Efficient Compression of Neural Networks.</em>
							In <strong>CVPR 2021</strong> (oral presentation)<br />
							We search for functionally-equivalent, yet easier to compress networks to achieve state-of-the-art memory-to-accuracy tradeoffs in image classification and object detection.</p>
						</div>
						<div class="card-footer">
							<a href="https://arxiv.org/pdf/2010.15703.pdf"><i class="fa fa-file-pdf-o fa-lg"></i></a>
							<a href="https://arxiv.org/abs/2010.15703"><i class="ai ai-arxiv ai-lg"></i></a>
							<a href="https://github.com/uber-research/permute-quantize-finetune"><i class="fa fa-github fa-lg"></i></a>
							<a href="papers/bibtex/cvpr21.bib">.bib</a>
						</div>
					</div>
				</div>
				<div class="col-sm-6 col-lg-4 mb-4">
					<div class="card">
						<a href="imgs/icra20.png"><img class="card-img-top img-fluid" src="imgs/icra20.jpg" alt="Card image cap"></a>
						<div class="card-body">
							<h4 class="card-title">Pit30M</h4>
							<p class="card-text">
							<strong>Julieta Martinez</strong>, Sasha Doubov, Jack Fan, Ioan Andrei Bârsan, Shenlong Wang, Gellért Máttyus, and Raquel Urtasun.<br>
							<em>Pit30M: A Benchmark for Global Localization in the Age of Self-Driving Cars.</em>
							In <strong>ICRA 2020</strong> (best application paper runner-up)<br>
							We propose a dataset of 30 million images and LiDAR pairs to benchmark localization at city scale.</p>
						</div>
						<div class="card-footer">
							<a href="https://arxiv.org/pdf/2012.12437.pdf"><i class="fa fa-file-pdf-o fa-lg"></i></a>
							<a href="https://arxiv.org/abs/2012.12437"><i class="ai ai-arxiv ai-lg"></i></a>
							<a href="https://youtu.be/hJ6A_1YSITo"><i class="fa fa-youtube-play fa-lg"></i></a>
							<a href="papers/bibtex/icra19.bib">.bib</a>
						</div>
					</div>
				</div>
				<div class="col-sm-6 col-lg-4 mb-4">
					<div class="card">
						<a href="imgs/cvpr19.png"><img class="card-img-top img-fluid" src="imgs/cvpr19.png" alt="Card image cap"></a>
						<div class="card-body">
							<h4 class="card-title">Low-memory localization</h4>
							<p class="card-text">
							Xinkai Wei*, Ioan Andrei Bârsan*, Shenlong Wang*, <strong>Julieta Martinez</strong>, and Raquel Urtasun.<br>
							<em>Learning to Localize through Compressed Binary Maps.</em>
							In <strong>CVPR 2019</strong><br>
							We train neural networks to learn very low-memory maps useful for localization in self-driving.</p>
						</div>
						<div class="card-footer">
							<a href="https://arxiv.org/pdf/2012.10942.pdf"><i class="fa fa-file-pdf-o fa-lg"></i></a>
							<a href="https://arxiv.org/abs/2012.10942"><i class="ai ai-arxiv ai-lg"></i></a>
							<a href="https://www.youtube.com/watch?v=vL9F6qfwBFk"><i class="fa fa-youtube-play fa-lg"></i></a>
							<a href="papers/bibtex/cvpr19.bib">.bib</a>
						</div>
					</div>
				</div>
				<div class="col-sm-6 col-lg-4 mb-4">
					<div class="card">
						<a href="imgs/iccv18.png"></a>
						<div class="card-body">
							<h4 class="card-title">Faster and more accurate compressed nearest neighbour search</h4>
							<p class="card-text">
							<strong>Julieta Martinez</strong>, Shobhit Zakhmi, Holger H. Hoos and James J. Little.<br>
							<em>LSQ++: lower running time and higher recall in multi-codebook quantization.</em>
							In <strong>ECCV 2018</strong><br>
							We benchmark multi-codebook quantization (MCQ) approaches on an equal footing and propose two improvements that make MCQ faster and more accurate.</p>
						</div>
						<div class="card-footer">
							<a href="https://openaccess.thecvf.com/content_ECCV_2018/papers/Julieta_Martinez_LSQ_lower_runtime_ECCV_2018_paper.pdf"><i class="fa fa-file-pdf-o fa-lg"></i></a>
							<a href="https://github.com/una-dinosauria/Rayuela.jl"><i class="fa fa-github fa-lg"></i></a>
							<a href="papers/bibtex/eccv18.bib">.bib</a>
						</div>
					</div>
				</div>
				<div class="col-sm-6 col-lg-4 mb-4">
					<div class="card">
						<a href="imgs/iccv17.png"><img class="card-img-top img-fluid" src="imgs/iccv17.png" alt="Card image cap"></a>
						<div class="card-body">
							<h4 class="card-title">3d pose baseline</h4>
							<p class="card-text">
							<strong>Julieta Martinez</strong>, Rayat Hossain, Javier Romero and James J. Little.<br>
							<em>A simple yet effective baseline for 3d human pose estimation.</em>
							In <strong>ICCV 2017</strong> (28.9% acceptance rate)<br>
							We propose a simple deep learning baseline for 3d human pose estimation that outperforms the state of the art.</p>
						</div>
						<div class="card-footer">
							<a href="https://arxiv.org/pdf/1705.03098.pdf"><i class="fa fa-file-pdf-o fa-lg"></i></a>
							<a href="https://arxiv.org/abs/1705.03098"><i class="ai ai-arxiv ai-lg"></i></a>
							<a href="https://github.com/una-dinosauria/3d-pose-baseline"><i class="fa fa-github fa-lg"></i></a>
							<a href="https://www.youtube.com/watch?v=Hmi3Pd9x1BE"><i class="fa fa-youtube-play fa-lg"></i></a>
							<a href="papers/bibtex/arxiv17.bib">.bib</a>
						</div>
					</div>
				</div>
				<div class="col-sm-6 col-lg-4 mb-4">
					<div class="card">
						<a href="imgs/cvpr17.png"><img class="card-img-top img-fluid" src="imgs/cvpr17.png" alt="Card image cap"></a>
						<div class="card-body">
							<h4 class="card-title">Human motion prediction</h4>
							<p class="card-text">
							<strong>Julieta Martinez</strong>, Michael J. Black, Javier Romero.<br>
							<em>On human motion prediction using recurrent neural networks.</em>
							In <strong>CVPR 2017</strong> (29.84% acceptance rate)<br>
							We take a close look at deep recurrent approaches for human motion prediction, and propose a simple and scalable architecture that outperforms the state of the art.</p>
						</div>
						<div class="card-footer">
							<a href="https://arxiv.org/pdf/1705.02445.pdf"><i class="fa fa-file-pdf-o fa-lg"></i></a>
							<a href="https://arxiv.org/abs/1705.02445"><i class="ai ai-arxiv ai-lg"></i></a>
							<a href="https://github.com/una-dinosauria/human-motion-prediction"><i class="fa fa-github fa-lg"></i></a>
							<a href="https://youtu.be/JMFNws70onI"><i class="fa fa-youtube-play fa-lg"></i></a>
							<a href="papers/bibtex/cvpr17.bib">.bib</a>
						</div>
					</div>
				</div>
				<div class="col-sm-6 col-lg-4 mb-4">
					<div class="card">
						<a href="imgs/eccv16.png"><img class="card-img-top img-fluid" src="imgs/eccv16.png" alt="Card image cap"></a>
						<div class="card-body">
							<h4 class="card-title">Compressed nearest neighbour search</h4>
							<p class="card-text"><strong>Julieta Martinez</strong>, Joris Clement, Holger H. Hoos, James J. Little.<br>
							<em>Revisiting additive quantization.</em>
							In <strong>ECCV 2016</strong> (26.6% acceptance rate) <br>
							Additive quantization (AQ) is a promising vector compression approach for large-scale approximate nearest neighbour search. We introduce an optimization method for AQ that pushes it beyond the state of the art.</p>
						</div>
						<div class="card-footer">
							<a href="papers/eccv16.pdf"><i class="fa fa-file-pdf-o fa-lg"></i></a>
							<a href="https://github.com/una-dinosauria/local-search-quantization"><i class="fa fa-github fa-lg"></i></a>
							<a href="papers/bibtex/eccv16.bib">.bib</a>
						</div>
					</div>
				</div>
				<div class="col-sm-6 col-lg-4 mb-4">
					<div class="card">
						<a href="imgs/cvpr14.png"><img class="card-img-top img-fluid" src="imgs/cvpr14.png" alt="Card image cap"></a>
						<div class="card-body">
							<h4 class="card-title">3d pose from motion</h4>
							<p class="card-text">Ankur Gupta*, <strong>Julieta Martinez</strong>*, James J. Little, Robert J. Woodham.<br>
							<em>3D pose from motion for cross-view action recognition.</em>
							In <strong>CVPR 2014</strong> (29.88% acceptance rate)<br>
							An approach to improving cross-view action recognition by retrieving mocap given video sequences.</p>
						</div>
						<div class="card-footer">
							<a href="papers/cvpr14.pdf"><i class="fa fa-file-pdf-o fa-lg"></i></a>
							<a href="https://github.com/ubc-cvlab/mocap-dense-trajectories"><i class="fa fa-github fa-lg"></i></a>
							<a href="https://www.youtube.com/watch?v=7hur0Vr-7aA"><i class="fa fa-youtube-play fa-lg"></i></a>
							<a href="videos/mocap-trajectories-video.mp4"><i class="fa fa-file-video-o fa-lg" data-wow-delay=".5s"></i></a>
							<a href="papers/bibtex/ankur_cvpr_14.bib">.bib</a>
						</div>
					</div>
				</div>
			</div>
		
			<!-- <h2>Other papers</h2>
			<div class="row">
				<div class="col-md-4">
					<div class="card">
						<a href="imgs/wacv16.png"><img class="card-img-top img-fluid" src="imgs/wacv16.png" alt="Card image cap"></a>
						<div class="card-body">
							<h4 class="card-title">Mocap retrieval</h4>
							<p class="card-text">
							Ankur Gupta, John He, <strong>Julieta Martinez</strong>, James J. Little and Robert J. Woodham.<br>
							<em>Efficient video-based retrieval of human motion with flexible alignment.</em>
							In <strong>WACV 2016</strong><br>
							We formalize the problem of video-based mocap retrieval. We also investigate different retrieval methods for this task.</p>
						</div>
						<div class="card-footer">
							<a href="papers/wacv16.pdf"><i class="fa fa-file-pdf-o fa-lg"></i></a>
							<a href="https://www.cs.ubc.ca/labs/lci/v3dr/"><i class="fa fa-link fa-lg"></i></a>
							<a href="https://www.youtube.com/watch?v=YIdDOlxxe-M"><i class="fa fa-youtube-play fa-lg"></i></a>
							<a href="papers/bibtex/ankur_wacv_16.bib">.bib</a>
						</div>
					</div>
					<br/>
				</div>
				<div class="col-md-4">
					<div class="card">
						<a href="imgs/stacked.png"><img class="card-img-top img-fluid" src="imgs/stacked.png" alt="Card image cap"></a>
						<div class="card-body">
							<h4 class="card-title">Stacked quantizers</h4>
							<p class="card-text"><strong>Julieta Martinez</strong>, Holger H. Hoos and James J. Little.
							<em>Stacked quantizers for compositional vector compression.</em> In <strong>arxiv</strong>  (2014)<br>
							Some of my early attempts to improve multi-codebook quantization. This approach is equivalent to <a href="https://link.springer.com/article/10.1007/s00530-015-0470-9">enhanced RVQ</a>, and has been superceeded by our work on revisiting AQ. The code is very accessible though!</p>
						</div>
						<div class="card-footer">
							<a href="https://arxiv.org/pdf/1411.2173.pdf"><i class="fa fa-file-pdf-o fa-lg"></i></a>
							<a href="https://arxiv.org/1411.2173"><i class="ai ai-arxiv ai-lg"></i></a>
							<a href="https://github.com/una-dinosauria/stacked-quantizers"><i class="fa fa-github fa-lg"></i></a>
							<a href="papers/bibtex/ankur_wacv_16.bib">.bib</a>
						</div>
					</div>
				</div>
			</div>
			<br> -->
		
			<!-- <h2>Yet more papers</h2>
			<div class="list-group">
				<div class="list-group-item flex-column align-items-start">
					<div class="d-flex w-100 justify-content-between">
						<h5 class="mb-1">Solving multi-codebook quantization in the GPU |
							<a href="papers/eccvw16.pdf"><i class="fa fa-file-pdf-o fa-lg"></i></a>
							<a href="https://github.com/una-dinosauria/local-search-quantization"><i class="fa fa-github fa-lg"></i></a>
							<a href="papers/bibtex/eccvw16.bib">.bib</a>
						</h5>
					</div>
					<p class="mb-1">
					<strong>Julieta Martinez</strong>, Holger H. Hoos and James J. Little. In <strong>4th Workshop on Web-scale Vision and Social Media (VSM), at ECCV 2016</strong>.<br>
					Complement to our work on Revisiting AQ. Details our GPU implementation.
					</p>
				</div>
				<div class="list-group-item flex-column align-items-start">
					<div class="d-flex w-100 justify-content-between">
						<h5 class="mb-1">
							Hash bank |
							<a href="papers/wacv15.pdf"><i class="fa fa-file-pdf-o fa-lg"></i></a>
							<a href="https://www.cs.ubc.ca/labs/lci/v3dr/"><i class="fa fa-link fa-lg"></i></a>
							<a href="papers/bibtex/ankur_wacv_16.bib">.bib</a>
						</h5>
					</div>
					<p class="mb-1">Frederick Tung, <strong>Julieta Martinez</strong>, Holger H. Hoos and James J. Little. In <strong>WACV 2015</strong>.<br>
					A vector is mapped to one of many hash functions, which improves accuracy at increased query time.</p>
				</div>
				<div class="list-group-item flex-column align-items-start">
					<div class="d-flex w-100 justify-content-between">
						<h5 class="mb-1">BO on FLANN |
							<a href="papers/wacv14.pdf"><i class="fa fa-file-pdf-o fa-lg"></i></a>
							<a href="papers/bibtex/wacv14.bib">.bib</a>
						</h5>
					</div>
					<p class="mb-1"><strong>Julieta Martinez</strong>, James J. Little and Nando de Freitas. In <strong>WACV 2014</strong>.<br>
					We showed that Bayesian optimization with <a href="https://en.wikipedia.org/wiki/Gaussian_process">Gaussian processes</a> would be a great addition to <a href="https://www.cs.ubc.ca/research/flann/">FLANN</a>.</p>
				</div>
			</div>
			<br> -->
		
			<!-- Projects Row -->
			<h2>Misc</h2>
			<div class="row">
				<div class="col-md-4">
					<div class="card">
						<a href="https://github.com/una-dinosauria/deepviz"><img class="card-img-top img-fluid" src="imgs/dviz.png" alt="Card image cap"></a>
						<div class="card-body">
							<h4 class="card-title">DeepViz</h4>
							<p class="card-text">
							My information visualization final project, taught by the wonderful <a href="https://www.cs.ubc.ca/~tmm/">Tamara Munzner</a>. A javascript visualization tool for image retrieval (2015).</p>
						</div>
						<div class="card-footer">
							<a href="https://www.cs.ubc.ca/~tmm/courses/547-15/projects/julieta/report.pdf"><i class="fa fa-file-pdf-o fa-lg"></i></a>
							<a href="https://github.com/una-dinosauria/deepviz"><i class="fa fa-github fa-lg"></i></a>
						</div>
					</div>
					<br/>
				</div>
				<div class="col-md-4">
					<div class="card">
						<a href="https://una-dinosauria.github.io/efros-and-leung-js/"><img class="card-img-top img-fluid" src="imgs/donkey.jpg" alt="Card image cap"></a>
						<div class="card-body">
							<h4 class="card-title">Efros and Leung JS</h4>
							<p class="card-text">
							A javascript implementation of a <a href="https://www2.eecs.berkeley.edu/Research/Projects/CS/vision/papers/efros-iccv99.pdf">classic method for texture synthesis</a> (2015).</p>
						</div>
						<div class="card-footer">
							<a href="https://github.com/una-dinosauria/efros-and-leung-js/"><i class="fa fa-github fa-lg"></i></a>
						</div>
					</div>
					<br/>
				</div>
				<div class="col-md-4">
					<div class="card">
						<a href="http://una-dinosauria.github.io/game%20theory/2014/09/03/better-than-tit-for-that"><img class="card-img-top img-fluid" src="imgs/pavlov.png" alt="Card image cap"></a>
						<div class="card-body">
							<h4 class="card-title">Pavlov is no simpleton</h4>
							<p class="card-text">
							I tried to reproduce the results of a <a href="http://abel.math.harvard.edu/archive/153_fall_04/Additional_reading_material/A_strategy_of_winstay_loseshift_that_out_performs_titfortat_in_the_Prisoners_Dilemma_game.pdf.pdf">1993 paper on evolutionary dynamics</a> by Sigmund and Novak. I also wrote a <a href="https://una-dinosauria.github.io/game%20theory/2014/09/03/better-than-tit-for-that">blog post</a> about it (2014).<br>
						</div>
						<div class="card-footer">
							<a href="https://github.com/una-dinosauria/better-than-tit-for-tat"><i class="fa fa-github fa-lg"></i></a>
						</div>
					</div>
					<br/>
				</div>
			</div>
			<br>
		
			<!-- NOT RESEARCH -->
			<h2>rand()</h2>
			<div class="row">
				<div class="col-lg-12">
					<div class="list-group">
						<div class="list-group-item">
							<p>I am/have served as a reviewer for CVPR, ECCV, ICCV, IROS, ICRA, NeurIPS, AAAI, IJCAI, CVIU, and TPAMI.<p>
						</div>
						<div class="list-group-item">
							<p>I have done science outreach with <a href="https://www.cs.ubc.ca/girlsmarts4tech/">GIRLsmarts4tech</a>, <a href="https://twitter.com/yoknapathawa/status/822732832766164993">UBC women in science</a> and <a href="https://twitter.com/realscientists">@realscientists</a>.<p>
						</div>
						<div class="list-group-item">
							<p>On the fall of 2014 I started organizing CVRG, the <a href="https://www.cs.ubc.ca/labs/lci/cvrg/">Computer Vision Reading Group</a> at UBC.</p>
						</div>
						<!-- <div class="list-group-item">
							<p class="list-group-item-text">On the summer of 2014 I started <a href="https://una-dinosauria.github.io">blogging</a></p>
						</div>
							-->
						<!-- <div class="list-group-item">
							<p>On the summer of 2013 I made a <a href="https://chrome.google.com/webstore/detail/pin-a-pdf/gkmajjfpbcmhocnmkbfoiieenlmdkapi">chrome extension</a> that lets you share pdfs on <a href="https://www.pinterest.com/">Pinterest</a>. Take a look at my
							<a href="https://www.pinterest.com/jltmtz/research/">research board</a>!</p>
						</div> -->
					</div>
				</div>
			</div>
		
		
			<!-- FOOTER -->
			<footer>
				<div class="row">
					<div class="col-lg-12">
						<p></p>
					</div>
				</div>
			</footer>
		
			<!-- close container -->
		</div>
		</main>

		<!-- masonry -->
		<script src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha384-GNFwBvfVxBkLMJpYMOABq3c+d3KnQxudP/mGPkzpZSTYykLBNsZEnG2D9G/X/+7D" crossorigin="anonymous" async></script>
		<!-- bootstrap with popper js -->
		<script src="https://cdn.jsdelivr.net/npm/@popperjs/core@2.11.5/dist/umd/popper.min.js" integrity="sha384-Xe+8cL9oJa6tN/veChSP7q+mnSPaj5Bcu9mPX5F5xIGE0DVittaqT5lorf0EI7Vk" crossorigin="anonymous"></script>
		<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.2.0-beta1/dist/js/bootstrap.min.js" integrity="sha384-kjU+l4N0Yf4ZOJErLsIcvOU2qSb74wXpOhqTvwVx3OElZRweTnQ6d31fXEoRD1Jy" crossorigin="anonymous"></script>
	</body>

</html>
